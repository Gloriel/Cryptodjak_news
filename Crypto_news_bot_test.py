import os
import asyncio
import logging
import hashlib
import imghdr
from typing import Optional, Dict, Any, List, Set
from urllib.parse import urljoin, urlparse
from datetime import datetime
from functools import lru_cache
import aiohttp
import feedparser
from bs4 import BeautifulSoup
from telegram import Bot, InputMediaPhoto
from telegram.constants import ParseMode
from dotenv import load_dotenv

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('bot.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class CryptoNewsBot:
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            load_dotenv()

            # –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
            self.bot_token = os.getenv("BOT_TOKEN")
            self.channel_id = os.getenv("CHANNEL_ID")
            self.rss_url = os.getenv("RSS_URL")
            
            if not all([self.bot_token, self.channel_id, self.rss_url]):
                raise ValueError("–ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            self.bot = Bot(token=self.bot_token)
            self.session: Optional[aiohttp.ClientSession] = None

            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            self.default_images = [
                "https://cryptonews.com/wp-content/uploads/2023/04/crypto-news.jpg",
                "https://images.unsplash.com/photo-1639762681057-408e52192e55"
            ]
            self.current_image_index = 0
            self.max_image_size = 5 * 1024 * 1024  # 5MB
            self.allowed_image_types = {
                'image/jpeg', 'image/png', 'image/webp', 'image/gif'
            }

            # –°–∏—Å—Ç–µ–º–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            self.check_interval = max(1800, int(os.getenv("CHECK_INTERVAL", "10800")))  # –º–∏–Ω–∏–º—É–º 30 –º–∏–Ω—É—Ç
            self.request_timeout = 15
            self.max_retries = 3
            self.retry_delay = 2

            # –ö—ç—à–∏ –∏ —á–µ—Ä–Ω—ã–µ —Å–ø–∏—Å–∫–∏
            self.broken_urls: Set[str] = set()
            self.sent_news_cache = lru_cache(maxsize=100)()

            logger.info("–ë–æ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
        except Exception as e:
            logger.critical(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            raise

    async def initialize(self) -> None:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏"""
        try:
            self.session = aiohttp.ClientSession(
                headers={
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
                    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8"
                },
                timeout=aiohttp.ClientTimeout(total=self.request_timeout),
                connector=aiohttp.TCPConnector(ssl=False, limit=10)
            )
            logger.info("–°–µ—Å—Å–∏—è aiohttp —Å–æ–∑–¥–∞–Ω–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–µ—Å—Å–∏–∏: {e}")
            raise

    async def close(self) -> None:
        """–ì—Ä–∞—Ü–∏–æ–∑–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã"""
        try:
            if self.session and not self.session.closed:
                await self.session.close()
                logger.info("–°–µ—Å—Å–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–∫—Ä—ã—Ç–∞")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ —Å–µ—Å—Å–∏–∏: {e}")

    def _clean_html(self, html: str, max_length: int = 800) -> str:
        """–û—á–∏—Å—Ç–∫–∞ HTML —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç XSS –∏ –∏–∑–±—ã—Ç–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        if not html:
            return ""

        try:
            soup = BeautifulSoup(html, "html.parser")
            
            # –£–¥–∞–ª–µ–Ω–∏–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –æ–ø–∞—Å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            for element in soup.find_all():
                if element.name in ['script', 'style', 'iframe', 'object', 'embed']:
                    element.decompose()
                elif element.name == 'a' and element.get('href', '').startswith('javascript:'):
                    element.decompose()
                elif element.name == 'img' and not element.get('src', '').startswith(('http://', 'https://')):
                    element.decompose()

            # –ü–æ–ª—É—á–µ–Ω–∏–µ —á–∏—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            text = '\n'.join(
                p.get_text().strip() 
                for p in soup.find_all(['p', 'br', 'div']) 
                if p.get_text().strip()
            )
            
            # –ó–∞—â–∏—Ç–∞ –æ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫
            text = ' '.join(text.split())
            return text[:max_length] + ('...' if len(text) > max_length else '')
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ HTML: {e}")
            return html[:max_length]

    def _validate_url(self, url: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ URL –Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å"""
        try:
            result = urlparse(url)
            return all([
                result.scheme in ('http', 'https'),
                result.netloc,
                not result.netloc.startswith(('127.', 'localhost', '192.168.', '10.'))
            ])
        except:
            return False

    async def _verify_image(self, url: str) -> bool:
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        if not self._validate_url(url) or url in self.broken_urls:
            return False

        try:
            # –ü–µ—Ä–≤–∏—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ HEAD
            async with self.session.head(
                url, 
                allow_redirects=True,
                timeout=aiohttp.ClientTimeout(total=10)
            ) as resp:
                if resp.status != 200:
                    self.broken_urls.add(url)
                    return False

                content_type = resp.headers.get('Content-Type', '').lower()
                content_length = int(resp.headers.get('Content-Length', '0'))

                if not (any(ct in content_type for ct in self.allowed_image_types) and
                        0 < content_length <= self.max_image_size):
                    self.broken_urls.add(url)
                    return False

            # –í—Ç–æ—Ä–∏—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–≤—ã—Ö –±–∞–π—Ç–æ–≤
            async with self.session.get(
                url,
                timeout=aiohttp.ClientTimeout(total=15)
            ) as resp:
                if resp.status != 200:
                    self.broken_urls.add(url)
                    return False

                # –ß–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                chunk = await resp.content.read(128)
                if not chunk:
                    self.broken_urls.add(url)
                    return False

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–≥–Ω–∞—Ç—É—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                image_type = imghdr.what(None, chunk)
                if not image_type:
                    self.broken_urls.add(url)
                    return False

            return True
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {url}: {e}")
            self.broken_urls.add(url)
            return False

    async def _get_safe_image(self, html: str, base_url: str) -> str:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ fallback-–≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏"""
        try:
            soup = BeautifulSoup(html, "html.parser")
            
            # –ü–æ–∏—Å–∫ –ø–æ OpenGraph –∏ Twitter Cards
            for meta in soup.find_all('meta'):
                if meta.get('property') in ['og:image', 'twitter:image']:
                    img_url = urljoin(base_url, meta.get('content', ''))
                    if await self._verify_image(img_url):
                        return img_url

            # –ü–æ–∏—Å–∫ –ø–æ —Ç–µ–≥–∞–º img
            for img in soup.find_all('img', src=True):
                img_url = urljoin(base_url, img['src'])
                if await self._verify_image(img_url):
                    return img_url

            # Fallback –Ω–∞ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            return await self._get_next_default_image()
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return await self._get_next_default_image()

    async def _get_next_default_image(self) -> str:
        """–¶–∏–∫–ª–∏—á–µ—Å–∫–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ñ–æ–ª—Ç–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        img = self.default_images[self.current_image_index]
        self.current_image_index = (self.current_image_index + 1) % len(self.default_images)
        return img

    async def fetch_latest_news(self) -> Optional[Dict[str, Any]]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∫–æ–¥–∏—Ä–æ–≤–æ–∫"""
        try:
            async with self.session.get(
                self.rss_url,
                timeout=aiohttp.ClientTimeout(total=15)
            ) as response:
                if response.status != 200:
                    logger.error(f"–û—à–∏–±–∫–∞ RSS: HTTP {response.status}")
                    return None

                # –ê–≤—Ç–æ–¥–µ—Ç–µ–∫—Ç –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                content = await response.text(errors='replace')
                feed = feedparser.parse(content)

                if not feed.entries:
                    logger.info("–ù–æ–≤–æ—Å—Ç–µ–π –≤ RSS –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                    return None

                entry = feed.entries[0]
                published = entry.get('published_parsed') or entry.get('updated_parsed')
                timestamp = datetime(*published[:6]).timestamp() if published else datetime.now().timestamp()

                # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID —Å —É—á–µ—Ç–æ–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –∏ –≤—Ä–µ–º–µ–Ω–∏
                news_id = hashlib.sha256(
                    f"{entry.title}{entry.link}{timestamp}".encode('utf-8')
                ).hexdigest()

                return {
                    'id': news_id,
                    'title': entry.get('title', '–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞'),
                    'link': entry.link,
                    'description': entry.get('description', ''),
                    'published': entry.get('published', '')
                }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
            return None

    async def prepare_post(self, news_item: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–æ—Å—Ç–∞ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –æ—à–∏–±–æ–∫ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        try:
            title = self._clean_html(news_item['title'], 100)
            description = self._clean_html(news_item['description'])
            link = news_item['link']

            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image_url = await self._get_safe_image(news_item['description'], news_item['link'])

            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤
            message = (
                f"<b>{title}</b>\n\n"
                f"{description}\n\n"
                f"üìÖ <i>{news_item.get('published', '')}</i>\n"
                f"üîó <a href='{link}'>–ß–∏—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é</a>\n"
                f"#–ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞ #–ù–æ–≤–æ—Å—Ç–∏"
            )

            return {
                'id': news_item['id'],
                'image_url': image_url,
                'message': message
            }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –ø–æ—Å—Ç–∞: {e}")
            return None

    async def send_post(self, post: Dict[str, Any]) -> bool:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –ø–æ—Å—Ç–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º fallback"""
        if not post:
            return False

        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
        if post.get('image_url'):
            for attempt in range(self.max_retries):
                try:
                    await self.bot.send_photo(
                        chat_id=self.channel_id,
                        photo=post['image_url'],
                        caption=post['message'],
                        parse_mode=ParseMode.HTML,
                        write_timeout=20,
                        connect_timeout=15
                    )
                    return True
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–æ—Ç–æ (–ø–æ–ø—ã—Ç–∫–∞ {attempt+1}): {e}")
                    if attempt < self.max_retries - 1:
                        await asyncio.sleep(self.retry_delay * (attempt + 1))

        # Fallback –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        try:
            await self.bot.send_message(
                chat_id=self.channel_id,
                text=post['message'],
                parse_mode=ParseMode.HTML,
                disable_web_page_preview=True,
                write_timeout=15,
                connect_timeout=10
            )
            return True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
            return False

    async def run(self) -> None:
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç —Å–±–æ–µ–≤"""
        await self.initialize()
        
        try:
            while True:
                try:
                    logger.info("–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π...")
                    news_item = await self.fetch_latest_news()
                    
                    if news_item and not self.sent_news_cache.get(news_item['id']):
                        logger.info(f"–ù–∞–π–¥–µ–Ω–∞ –Ω–æ–≤–æ—Å—Ç—å: {news_item['title'][:50]}...")
                        post = await self.prepare_post(news_item)
                        
                        if post and await self.send_post(post):
                            self.sent_news_cache[news_item['id']] = True
                            logger.info("–ù–æ–≤–æ—Å—Ç—å —É—Å–ø–µ—à–Ω–æ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞")
                        else:
                            logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å –Ω–æ–≤–æ—Å—Ç—å")
                    
                    logger.info(f"–û–∂–∏–¥–∞–Ω–∏–µ {self.check_interval//3600} —á–∞—Å–æ–≤...")
                    await asyncio.sleep(self.check_interval)
                    
                except asyncio.CancelledError:
                    raise
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e}")
                    await asyncio.sleep(min(300, self.check_interval))  # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
                    
        except asyncio.CancelledError:
            logger.info("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ –∑–∞–ø—Ä–æ—Å—É")
        except Exception as e:
            logger.critical(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        finally:
            await self.close()

async def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ —Å –≥–ª–æ–±–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    bot = CryptoNewsBot()
    try:
        await bot.run()
    except KeyboardInterrupt:
        logger.info("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.critical(f"–§–∞—Ç–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
    finally:
        logger.info("–†–∞–±–æ—Ç–∞ –±–æ—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

if __name__ == "__main__":
    asyncio.run(main())