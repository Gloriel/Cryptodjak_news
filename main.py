import os
import sys
import asyncio
import logging
import hashlib
import re
import html
from typing import Optional, Dict, Any, List, Set, Tuple
from datetime import datetime, timedelta, timezone
from time import mktime

import aiohttp
import feedparser
from dotenv import load_dotenv
from telegram import Bot
from telegram.constants import ParseMode
from telegram.error import RetryAfter, TimedOut, NetworkError, BadRequest


# ========= –õ–û–ì–ò =========
class SecurityFilter(logging.Filter):
    def filter(self, record):
        if hasattr(record, 'msg'):
            sensitive_terms = ['BOT_TOKEN', 'token', 'password', 'secret']
            msg_str = str(record.msg)
            for term in sensitive_terms:
                if term in msg_str:
                    record.msg = msg_str.replace(term, '***')
        return True


logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('bot.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)
logger.addFilter(SecurityFilter())


# ========= –ë–û–¢ =========
class CryptoNewsBot:
    def __init__(self):
        load_dotenv()

        self.bot_token = os.getenv("BOT_TOKEN")
        self.channel_id = os.getenv("CHANNEL_ID")

        if not self.bot_token or not self.channel_id:
            missing = []
            if not self.bot_token:
                missing.append("BOT_TOKEN")
            if not self.channel_id:
                missing.append("CHANNEL_ID")
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è: {', '.join(missing)}")

        # –°—Ç–∞—Ä—Ç–æ–≤—ã–π –ø—É–ª —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –ª–µ–Ω—Ç
        self.rss_feeds: List[str] = [
            "https://ru.cointelegraph.com/feed/",
            "https://cryptodirectories.com/ru/blog/feed/",
            "https://coinspot.io/feed/",
            "https://bitnovosti.com/feed/",
            "https://coinlife.com/feed/",
            "https://mining-bitcoin.ru/feed/",
            "https://cryptofeed.ru/feed/",
            "https://bitcoininfo.ru/feed/",
            "https://cryptocat.org/feed/",
            "https://blockchain24.ru/feed/",
            "https://cryptorussia.ru/feed/",
            "https://bitcoinist.ru/feed/",
        ]

        self.bot = Bot(token=self.bot_token)
        self.session: Optional[aiohttp.ClientSession] = None

        # –ß–∞—Å—Ç–æ—Ç—ã
        self.check_interval = 15 * 60       # –∫–∞–∂–¥—ã–µ 15 –º–∏–Ω—É—Ç –æ–ø—Ä–æ—Å –ª–µ–Ω—Ç
        self.post_interval = 60 * 60        # –º–∏–Ω–∏–º—É–º 1 —á–∞—Å –º–µ–∂–¥—É –ø–æ—Å—Ç–∞–º–∏
        self.request_timeout = 20

        # –õ–∏–º–∏—Ç—ã/—Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self.max_posts_per_day = 5
        self.posts_today = 0
        self.last_reset_date = datetime.now().date()
        self.last_post_time: Optional[datetime] = None

        # –£—á—ë—Ç –∏ —Å—Ç–∞—Ç—É—Å –ª–µ–Ω—Ç
        self.sent_news: Set[str] = set()  # —Ö—ç—à–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö
        self.feed_usage: Dict[str, int] = {f: 0 for f in self.rss_feeds}
        self.feed_errors: Dict[str, int] = {f: 0 for f in self.rss_feeds}
        self.feed_quarantine_until: Dict[str, datetime] = {}  # –∫–æ–≥–¥–∞ –º–æ–∂–Ω–æ —Å–Ω–æ–≤–∞ –ø—Ä–æ–±–æ–≤–∞—Ç—å –ª–µ–Ω—Ç—É

        self.stats = {
            "total_posts": 0,
            "failed_posts": 0,
            "last_success": None,
            "feed_stats": {f: 0 for f in self.rss_feeds}
        }

        logger.info(f"–ë–æ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –õ–µ–Ω—Ç: {len(self.rss_feeds)}")

    # ---------- HTTP ----------
    async def initialize(self) -> None:
        self.session = aiohttp.ClientSession(
            headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
                "Accept-Language": "ru-RU,ru;q=0.9,en;q=0.8",
            },
            timeout=aiohttp.ClientTimeout(total=self.request_timeout),
            connector=aiohttp.TCPConnector(ssl=True, limit=10)
        )
        logger.info("HTTP-—Å–µ—Å—Å–∏—è —Å–æ–∑–¥–∞–Ω–∞")

    async def close(self) -> None:
        if self.session and not self.session.closed:
            await self.session.close()
            logger.info("HTTP-—Å–µ—Å—Å–∏—è –∑–∞–∫—Ä—ã—Ç–∞")

    # ---------- –£–¢–ò–õ–ò–¢–´ ----------
    @staticmethod
    def _letters_and_digits(text: str) -> str:
        return ''.join(ch for ch in text if ch.isalnum())

    def _is_russian_text(self, text: str) -> bool:
        """–¢–µ–∫—Å—Ç —Å—á–∏—Ç–∞–µ—Ç—Å—è —Ä—É—Å—Å–∫–∏–º, –µ—Å–ª–∏ ‚â• 30% –∫–∏—Ä–∏–ª–ª–∏—Ü—ã —Å—Ä–µ–¥–∏ –±—É–∫–≤/—Ü–∏—Ñ—Ä."""
        if not text:
            return False
        core = self._letters_and_digits(text)
        if not core:
            return False
        russian = re.findall(r'[–∞-—è–ê-–Ø—ë–Å]', core)
        return (len(russian) / max(1, len(core))) >= 0.30

    @staticmethod
    def _clean_text(text: str, max_length: int = 600) -> str:
        if not text:
            return ""
        try:
            no_tags = re.sub(r'<[^>]+>', '', text)
            unesc = html.unescape(no_tags)
            compact = ' '.join(unesc.split())
            if len(compact) > max_length:
                compact = compact[:max_length].rstrip() + '‚Ä¶'
            return compact
        except Exception:
            return (text or "")[:max_length]

    @staticmethod
    def _escape_html(text: str) -> str:
        return html.escape(text or "")

    @staticmethod
    def _domain_of(url: str) -> str:
        try:
            from urllib.parse import urlparse
            netloc = urlparse(url).netloc.lower()
            return netloc.removeprefix('www.')
        except Exception:
            return ""

    def _reset_daily_if_needed(self) -> None:
        today = datetime.now().date()
        if today != self.last_reset_date:
            self.posts_today = 0
            self.last_reset_date = today
            logger.info("–°–±—Ä–æ—Å –¥–Ω–µ–≤–Ω–æ–≥–æ —Å—á—ë—Ç—á–∏–∫–∞ –ø–æ—Å—Ç–æ–≤")

    def _seconds_until_next_post(self) -> int:
        if not self.last_post_time:
            return 0
        elapsed = (datetime.now() - self.last_post_time).total_seconds()
        remain = int(self.post_interval - elapsed)
        return max(0, remain)

    def _can_post_now(self) -> bool:
        self._reset_daily_if_needed()
        if self.posts_today >= self.max_posts_per_day:
            logger.info(f"–î–Ω–µ–≤–Ω–æ–π –ª–∏–º–∏—Ç: {self.posts_today}/{self.max_posts_per_day}")
            return False
        return self._seconds_until_next_post() == 0

    def _news_id(self, entry: Dict[str, Any]) -> str:
        base = entry.get('link') or entry.get('id') or (entry.get('title', '') + entry.get('published', ''))
        return hashlib.sha256(base.encode('utf-8', errors='ignore')).hexdigest()[:16]

    @staticmethod
    def _parse_date(entry: Dict[str, Any]) -> Optional[datetime]:
        """–ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç—É –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∫–∞–∫ naive-local datetime."""
        tm = None
        if 'published_parsed' in entry and entry['published_parsed']:
            tm = entry['published_parsed']
        elif 'updated_parsed' in entry and entry['updated_parsed']:
            tm = entry['updated_parsed']

        if tm:
            try:
                # mktime –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç localtime; –¥–µ–ª–∞–µ–º naive –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –∑–æ–Ω–µ
                return datetime.fromtimestamp(mktime(tm))
            except Exception:
                pass
        return None

    # ---------- –ü–†–û–ì–†–ï–í ----------
    async def test_rss_feeds(self) -> List[str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–µ–Ω—Ç—ã –∏ –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ —Ç–µ, –≥–¥–µ –µ—Å—Ç—å —Ä—É—Å—Å–∫–∏–µ –∑–∞–ø–∏—Å–∏."""
        logger.info("–¢–µ—Å—Ç–∏—Ä—É–µ–º RSS-–ª–µ–Ω—Ç—ã‚Ä¶")
        ok: List[str] = []
        for url in self.rss_feeds:
            try:
                async with self.session.get(url, timeout=self.request_timeout) as resp:
                    if resp.status != 200:
                        logger.warning(f"{url} ‚Äî HTTP {resp.status}")
                        continue
                    content = await resp.read()
                    parsed = feedparser.parse(content)
                    titles = [e.get('title', '') for e in parsed.entries[:5]]
                    if parsed.entries and any(self._is_russian_text(t) for t in titles):
                        ok.append(url)
                        logger.info(f"‚úÖ {url} ‚Äî —Ä–∞–±–æ—Ç–∞–µ—Ç, –µ—Å—Ç—å —Ä—É—Å—Å–∫–∏–µ –∑–∞–ø–∏—Å–∏")
                    else:
                        logger.warning(f"‚ö†Ô∏è {url} ‚Äî –∑–∞–ø–∏—Å–µ–π –º–∞–ª–æ/–Ω–µ—Ç —Ä—É—Å—Å–∫–∏—Ö")
            except Exception as e:
                logger.warning(f"‚ùå {url} ‚Äî –æ—à–∏–±–∫–∞: {e!r}")
        logger.info(f"–ì–æ—Ç–æ–≤—ã: {len(ok)}/{len(self.rss_feeds)}")
        return ok

    # ---------- –í–´–ë–û–† –õ–ï–ù–¢–´ ----------
    def _eligible_feeds(self) -> List[str]:
        now = datetime.now()
        eligible = []
        for f in self.rss_feeds:
            until = self.feed_quarantine_until.get(f)
            if until and now < until:
                # –µ—â—ë –≤ –∫–∞—Ä–∞–Ω—Ç–∏–Ω–µ
                continue
            eligible.append(f)
        return eligible

    def _get_next_feed(self) -> Optional[str]:
        eligible = self._eligible_feeds()
        if not eligible:
            return None
        # –±—Ä–∞—Ç—å —Ç—É, —á—Ç–æ —Ä–µ–∂–µ –≤—Å–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞—Å—å
        min_usage = min(self.feed_usage.get(f, 0) for f in eligible)
        candidates = [f for f in eligible if self.feed_usage.get(f, 0) == min_usage]
        import random
        chosen = random.choice(candidates)
        self.feed_usage[chosen] = self.feed_usage.get(chosen, 0) + 1
        logger.info(f"–õ–µ–Ω—Ç–∞ –≤—ã–±—Ä–∞–Ω–∞: {chosen} (–∏—Å–ø.: {self.feed_usage[chosen]})")
        return chosen

    def _quarantine_feed(self, feed: str):
        """–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π –±—ç–∫–æ—Ñ—Ñ –¥–ª—è –ª–µ–Ω—Ç—ã."""
        self.feed_errors[feed] = self.feed_errors.get(feed, 0) + 1
        tries = self.feed_errors[feed]
        # 10–º–∏–Ω, 30–º–∏–Ω, 1—á, 2—á, 4—á‚Ä¶
        backoff_minutes = min(240, int(10 * (1.5 ** (tries - 1))))
        until = datetime.now() + timedelta(minutes=backoff_minutes)
        self.feed_quarantine_until[feed] = until
        logger.warning(f"–ö–∞—Ä–∞–Ω—Ç–∏–Ω –ª–µ–Ω—Ç—ã {feed} –Ω–∞ {backoff_minutes} –º–∏–Ω (–æ—à–∏–±–æ–∫: {tries})")

    def _heal_feed(self, feed: str):
        if self.feed_errors.get(feed, 0) > 0:
            logger.info(f"–°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫–∏ –æ—à–∏–±–æ–∫ –¥–ª—è {feed}")
        self.feed_errors[feed] = 0
        self.feed_quarantine_until.pop(feed, None)

    # ---------- –ó–ê–ì–†–£–ó–ö–ê –ù–û–í–û–°–¢–ï–ô ----------
    async def fetch_latest_news(self, rss_url: str) -> List[Dict[str, Any]]:
        try:
            async with self.session.get(rss_url, timeout=self.request_timeout) as response:
                if response.status != 200:
                    logger.error(f"RSS {rss_url}: HTTP {response.status}")
                    self._quarantine_feed(rss_url)
                    return []

                content = await response.read()
                parsed = feedparser.parse(content)
                if not parsed.entries:
                    logger.error(f"–ü—É—Å—Ç–∞—è/–Ω–µ—á–∏—Ç–∞–µ–º–∞—è –ª–µ–Ω—Ç–∞: {rss_url}")
                    self._quarantine_feed(rss_url)
                    return []

                collected: List[Dict[str, Any]] = []
                for entry in parsed.entries[:30]:
                    title_raw = entry.get('title', '')
                    link = entry.get('link', '')
                    desc_raw = entry.get('description') or entry.get('summary') or entry.get('content', [{}])[0].get('value', '')

                    title = self._clean_text(title_raw, 140)
                    if not title or len(title) < 10 or not self._is_russian_text(title):
                        continue
                    if not link or not link.startswith(('http://', 'https://')):
                        continue

                    nid = self._news_id(entry)
                    if nid in self.sent_news:
                        continue

                    pub_dt = self._parse_date(entry)  # –º–æ–∂–µ—Ç –±—ã—Ç—å None
                    description = self._clean_text(desc_raw, 450)

                    collected.append({
                        "id": nid,
                        "title": title,
                        "link": link,
                        "description": description,
                        "published": pub_dt,
                        "source": rss_url,
                        "domain": self._domain_of(link) or self._domain_of(rss_url),
                    })

                # —Å–æ—Ä—Ç–∏—Ä—É–µ–º: —Å–≤–µ–∂–∏–µ –≤—ã—à–µ, –∑–∞—Ç–µ–º –¥–ª–∏–Ω–∞ –æ–ø–∏—Å–∞–Ω–∏—è (—á—É—Ç—å –±–æ–≥–∞—á–µ –∫–æ–Ω—Ç–µ–Ω—Ç)
                collected.sort(key=lambda x: (
                    0 if x["published"] else 1,
                    -(x["published"].timestamp() if x["published"] else 0),
                    -len(x["description"])
                ))

                if collected:
                    self._heal_feed(rss_url)
                    logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(collected)} –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {rss_url}")
                else:
                    logger.info(f"–ü–æ–¥—Ö–æ–¥—è—â–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –≤ {rss_url} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

                # –±–µ—Ä—ë–º –Ω–µ –±–æ–ª—å—à–µ —Ç—Ä—ë—Ö ‚Äî –Ω–µ —Å–ø–∞–º–∏–º
                return collected[:3]

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ RSS {rss_url}: {e!r}")
            self._quarantine_feed(rss_url)
            return []

    # ---------- –ü–û–î–ì–û–¢–û–í–ö–ê –ü–û–°–¢–ê ----------
    def _format_time_line(self, published: Optional[datetime], domain: str) -> str:
        parts = []
        if published:
            # –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é –¥–∞—Ç—É/–≤—Ä–µ–º—è –∫—Ä–∞—Ç–∫–æ
            parts.append(published.strftime("%d %b %Y, %H:%M"))
        if domain:
            parts.append(domain)
        if not parts:
            return ""
        return " ‚Ä¢ ".join(parts)

    def prepare_post(self, item: Dict[str, Any]) -> Dict[str, Any]:
        title_html = self._escape_html(item['title'])
        desc_html = self._escape_html(item['description'])
        link = item['link']
        meta_line = self._format_time_line(item.get("published"), item.get("domain", ""))

        # –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π, –Ω–æ ¬´—Ü–µ–ø–ª—è—é—â–∏–π¬ª —Ñ–æ—Ä–º–∞—Ç:
        # <b>–ó–∞–≥–æ–ª–æ–≤–æ–∫</b>
        # üïí –¥–∞—Ç–∞ ‚Ä¢ –∏—Å—Ç–æ—á–Ω–∏–∫
        # –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
        # –ß–∏—Ç–∞—Ç—å –¥–∞–ª–µ–µ ‚Üí (–∫–ª–∏–∫–∞–±–µ–ª—å–Ω–æ)
        message_lines = [f"<b>{title_html}</b>"]
        if meta_line:
            message_lines.append(f"üïí {self._escape_html(meta_line)}")
        if desc_html:
            message_lines.append(desc_html)
        message_lines.append(f'<a href="{link}">–ß–∏—Ç–∞—Ç—å –¥–∞–ª–µ–µ ‚Üí</a>')

        message = "\n\n".join(message_lines)

        return {
            'id': item['id'],
            'message': message,
            'title': item['title'],
            'source': item['source'],
        }

    # ---------- –û–¢–ü–†–ê–í–ö–ê ----------
    async def send_post(self, post: Dict[str, Any]) -> bool:
        max_attempts = 5
        delay = 2
        for attempt in range(1, max_attempts + 1):
            try:
                await self.bot.send_message(
                    chat_id=self.channel_id,
                    text=post['message'],
                    parse_mode=ParseMode.HTML,
                    disable_web_page_preview=False,
                )
                # —É—á—ë—Ç
                self.posts_today += 1
                self.stats['total_posts'] += 1
                self.stats['last_success'] = datetime.now()
                self.stats['feed_stats'][post['source']] += 1
                self.sent_news.add(post['id'])
                self.last_post_time = datetime.now()

                logger.info(f"‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {post['title'][:70]}‚Ä¶ ({self.posts_today}/{self.max_posts_per_day} —Å–µ–≥–æ–¥–Ω—è)")
                return True

            except RetryAfter as e:
                wait = int(getattr(e, "retry_after", delay))
                logger.warning(f"FloodWait/RetryAfter: –∂–¥—ë–º {wait} —Å–µ–∫")
                await asyncio.sleep(wait)
            except (TimedOut, NetworkError) as e:
                logger.warning(f"–°–µ—Ç—å (–ø–æ–ø—ã—Ç–∫–∞ {attempt}/{max_attempts}): {e}. –ñ–¥—ë–º {delay} —Å–µ–∫")
                await asyncio.sleep(delay)
                delay = min(delay * 2, 60)
            except BadRequest as e:
                logger.error(f"BadRequest: {e}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ—Å—Ç.")
                break
            except Exception as e:
                logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ—Å—Ç.")
                break

        self.stats['failed_posts'] += 1
        return False

    # ---------- –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ ----------
    async def run(self) -> None:
        await self.initialize()
        try:
            # 1) –ü—Ä–æ–≥—Ä–µ–≤: –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—á–∏–µ –ª–µ–Ω—Ç—ã
            working_feeds = await self.test_rss_feeds()
            if not working_feeds:
                logger.error("–ù–∏ –æ–¥–Ω–∞ RSS-–ª–µ–Ω—Ç–∞ –Ω–µ –ø—Ä–æ—à–ª–∞ —Ç–µ—Å—Ç. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏.")
                return

            # –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ—à–µ–¥—à–∏–µ —Ç–µ—Å—Ç –ª–µ–Ω—Ç—ã
            self.rss_feeds = list(working_feeds)
            # –ø–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º –∫–∞—Ä—Ç—ã —Å—Ç–∞—Ç—É—Å–∞ –ø–æ–¥ –Ω–æ–≤—ã–π –ø—É–ª
            self.feed_usage = {f: 0 for f in self.rss_feeds}
            self.feed_errors = {f: 0 for f in self.rss_feeds}
            self.feed_quarantine_until = {}
            self.stats["feed_stats"] = {f: 0 for f in self.rss_feeds}

            logger.info(f"–†–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å –ø—Ä–æ—à–µ–¥—à–∏–º–∏ —Ç–µ—Å—Ç –ª–µ–Ω—Ç–∞–º–∏: {len(self.rss_feeds)} —à—Ç.")
            logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω ‚úÖ")
            logger.info(f"–õ–∏–º–∏—Ç: {self.max_posts_per_day}/—Å—É—Ç–∫–∏, –ø–∞—É–∑–∞ –º–µ–∂–¥—É –ø–æ—Å—Ç–∞–º–∏: {self.post_interval // 60} –º–∏–Ω")

            # 2) –ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª
            while True:
                try:
                    # –¥–Ω–µ–≤–Ω–æ–π –ª–∏–º–∏—Ç
                    self._reset_daily_if_needed()
                    if self.posts_today >= self.max_posts_per_day:
                        tomorrow = datetime.combine(datetime.now().date() + timedelta(days=1), datetime.min.time())
                        sleep_s = max(60, int((tomorrow - datetime.now()).total_seconds()))
                        logger.info(f"–î–Ω–µ–≤–Ω–æ–π –ª–∏–º–∏—Ç –∏—Å—á–µ—Ä–ø–∞–Ω. –°–ø–∏–º –¥–æ –∑–∞–≤—Ç—Ä–∞: ~{sleep_s // 3600} —á")
                        await asyncio.sleep(sleep_s)
                        continue

                    # –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ø–æ—Å—Ç–∞–º–∏
                    wait = self._seconds_until_next_post()
                    if wait > 0:
                        nap = min(wait, max(300, self.check_interval))
                        logger.info(f"–†–∞–Ω–æ –ø–æ—Å—Ç–∏—Ç—å. –ñ–¥—ë–º {nap // 60} –º–∏–Ω")
                        await asyncio.sleep(nap)
                        continue

                    # –±–µ—Ä—ë–º –ª–µ–Ω—Ç—É
                    feed = self._get_next_feed()
                    if not feed:
                        # –≤—Å–µ –ª–µ–Ω—Ç—ã –≤ –∫–∞—Ä–∞–Ω—Ç–∏–Ω–µ; –∂–¥—ë–º –¥–æ –±–ª–∏–∂–∞–π—à–µ–≥–æ –≤—ã—Ö–æ–¥–∞ –∏–∑ –∫–∞—Ä–∞–Ω—Ç–∏–Ω–∞
                        if self.feed_quarantine_until:
                            nearest = min(self.feed_quarantine_until.values())
                            sleep_s = max(60, int((nearest - datetime.now()).total_seconds()))
                            logger.info(f"–í—Å–µ –ª–µ–Ω—Ç—ã –≤ –∫–∞—Ä–∞–Ω—Ç–∏–Ω–µ. –ñ–¥—ë–º {sleep_s // 60} –º–∏–Ω")
                            await asyncio.sleep(sleep_s)
                        else:
                            await asyncio.sleep(self.check_interval)
                        continue

                    news = await self.fetch_latest_news(feed)
                    if not news:
                        await asyncio.sleep(self.check_interval)
                        continue

                    # –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é (—Å–∞–º–∞—è —Å–≤–µ–∂–∞—è/–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è)
                    best = news[0]
                    post = self.prepare_post(best)
                    ok = await self.send_post(post)

                    if ok:
                        # –ø—É–±–ª–∏–∫–æ–≤–∞–ª–∏ ‚Äî –∂–¥—ë–º –ª–∏–±–æ check_interval, –ª–∏–±–æ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –æ–∫–Ω–∞ (—á—Ç–æ –º–µ–Ω—å—à–µ)
                        await asyncio.sleep(min(self.check_interval, self.post_interval))
                    else:
                        await asyncio.sleep(15 * 60)

                    # —Å–∞–Ω–∏—Ç–∞—Ä–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞
                    if len(self.sent_news) > 1000:
                        self.sent_news = set(list(self.sent_news)[-500:])
                        logger.info("–û—á–∏—â–µ–Ω –∫—ç—à –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π")

                    active_total = len(self._eligible_feeds())
                    logger.info(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {self.posts_today}/{self.max_posts_per_day} —Å–µ–≥–æ–¥–Ω—è, –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ª–µ–Ω—Ç: {active_total}/{len(self.rss_feeds)}")

                except asyncio.CancelledError:
                    raise
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e!r}")
                    await asyncio.sleep(min(1800, self.check_interval))

        finally:
            await self.close()
            logger.info("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚õî")


# ========= ENTRY =========
async def main():
    bot = CryptoNewsBot()
    try:
        await bot.run()
    except KeyboardInterrupt:
        logger.info("–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.critical(f"–§–∞—Ç–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞: {e!r}")
    finally:
        logger.info("–í—ã—Ö–æ–¥")


if __name__ == "__main__":
    # –î–ª—è Windows-–∫–æ–Ω—Å–æ–ª–∏
    if os.name == 'nt':
        try:
            sys.stdout.reconfigure(encoding='utf-8')
        except Exception:
            pass
    asyncio.run(main())
